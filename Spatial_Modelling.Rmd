---
title: "Spatial_Modelling"
author: "Luis Jaime Vidal Jordi"
date: "`r Sys.Date()`"
output: html_document
---

## Warning
**Run the RMD `Cleaning Pre-Processing` before.**

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This RMarkdown contains spatial modelling code elaborated for the Luis' Master Thesis. To follow the code it is highly advisable to previously read the thesis.

```{r}
# Some Libraries
library(INLA)
library(tidyverse)
library(magrittr)
library(xtable)
library(cowplot)
library(GGally)
```

## MODEL 2000
The following function takes a year as input and filters from `shp_world_filtered_unique` the corresponding year data.

```{r}
#_diff because there is a version selecting the time series but without differenciate
select_year_diff <- function(year = 2000){
  Year <- NULL
  E3CI_diff <- NULL
  E3CI <- NULL
  CO2 <- NULL
  GDP <- NULL
  GHG <- NULL
  FA <- NULL
  # Lo hacemos asi porque no he comprobado que el orden de los códigos sea el   mismo
  # De hecho dudo que lo sea
  for(i in shp_world_filtered_unique$color_code){
    cond <- which((clean_data$Code == i)&(clean_data$Year == year))
    E3CI_diff <- c(E3CI_diff,clean_data[cond,"E3CI_diff"])
    E3CI <- c(E3CI,clean_data[cond,"E3CI"])
    CO2 <- c(CO2, clean_data[cond,"CO2_diff"])
    GDP <- c(GDP, clean_data[cond,"GDP_diff"])
    GHG <- c(GHG, clean_data[cond,"GHG_diff"])
    FA <- c(FA, clean_data[cond,"FA_diff"])
    Year <- c(Year,year)}

  return(cbind(shp_world_filtered_unique,data.frame(E3CI_diff = E3CI_diff,E3CI = E3CI, GDP_diff = GDP, CO2_diff = CO2, GHG_diff = GHG, FA_diff = FA), Year = Year))
}
```

```{r}
select_year_diff2 <- function(year = 2000){
  Year <- NULL
  E3CI_diff <- NULL
  E3CI <- NULL
  CO2 <- NULL
  GDP <- NULL
  GHG <- NULL
  FA <- NULL
  idarea <- NULL
  idtime <- NULL
  # Lo hacemos asi porque no he comprobado que el orden de los códigos sea el   mismo
  # De hecho dudo que lo sea
  for(i in shp_world_filtered_unique$color_code){
    cond <- which((clean_data$Code == i)&(clean_data$Year == year))
    E3CI_diff <- c(E3CI_diff,clean_data[cond,"E3CI_diff"])
    E3CI <- c(E3CI,clean_data[cond,"E3CI"])
    CO2 <- c(CO2, clean_data[cond,"CO2_diff"])
    GDP <- c(GDP, clean_data[cond,"GDP_diff"])
    GHG <- c(GHG, clean_data[cond,"GHG_diff"])
    FA <- c(FA, clean_data[cond,"FA_diff"])
    idarea <- c(idarea, clean_data[cond, "idarea"])
    idtime <- c(idtime, clean_data[cond, "idtime"])
    Year <- c(Year,year)}

  return(cbind(shp_world_filtered_unique,data.frame(E3CI_diff = E3CI_diff,E3CI = E3CI, GDP_diff = GDP, CO2_diff = CO2, GHG_diff = GHG, FA_diff = FA), Year = Year, idarea = idarea, idtime = idtime))
}
```


```{r}
data_2000 <- select_year_diff(2000)
head(data_2000[,c("color_code","E3CI_diff","GDP_diff","CO2_diff","GHG_diff","FA_diff","Year")])
#View(data_2000)
```

#### Map - E3CI
```{r}
map2000 <- ggplot(data = data_2000) +
  geom_sf(aes(fill = E3CI)) + 
  labs(fill = "ERA5 - Risk Index") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2000_diff <- ggplot(data = data_2000) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "ERA5 - Risk Index") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2000
map2000_diff
```


#### Interactive Map E3CI

Cooler map

```{r}
library(leaflet)
cool_map2000 <- leaflet(data_2000) %>% addTiles()
pal <- colorNumeric(palette = "YlOrRd", domain = data_2000$E3CI)
cool_map2000 %>% 
  addPolygons(color = "grey", weight = 1, 
              fillColor = ~pal(E3CI), fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~E3CI, opacity = 0.5, 
            title = "E3CI", position = "bottomright")
```

#### Correlations
It is important to check the correlations between the covariates. If high correlations are found, we need to take this into account when considering whether or not to include it in the model.
```{r, message=FALSE}
numeric_2000 <- data_frame("E3CI" = data_2000$E3CI,
                           "GDP_diff" = data_2000$GDP_diff,
                           "CO2_diff" = data_2000$CO2_diff,
                           "GHG_diff" = data_2000$GHG_diff,
                           "FA_diff" = data_2000$FA_diff)


cor_2000 <- cor(numeric_2000)

library(ggcorrplot)
ggcorrplot(cor_2000, 
           method = "circle", 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           colors = c("blue", "white", "red"), 
           title = "Correlograma de la Matriz de Correlación")


library(scales)  # Para las escalas de colores
library(GGally)
# Crear el gráfico con ggpairs y personalización
ggpairs_plot <- ggpairs(data = data_2000, 
                        columns = c("E3CI", "GDP_diff", "CO2_diff", "GHG_diff", "FA_diff"),
                        title = "Pairwise Plot of Selected Variables",
                        lower = list(continuous = wrap("smooth", color = "blue")),
                        diag = list(continuous = wrap("densityDiag", fill = "blue", alpha = 0.5)),
                        upper = list(continuous = wrap("cor", size = 5))
) +
  theme_minimal() +  # Aplicar un tema minimalista
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),  # Centrar y estilizar el título
    axis.text = element_text(size = 10),  # Ajustar el tamaño del texto de los ejes
    axis.title = element_text(size = 12, face = "bold")  # Ajustar el tamaño y estilo del título de los ejes
  )

# Mostrar el gráfico
print(ggpairs_plot)
```


```{r}
library(INLA)
```

We are dealing with an irregular lattice. The first step is to create an adjacency matrix (neighbors matrix):

**Neighborhood Matrix**

By default, it will create a binary adjacency matrix, so that two regions are neighbors only if they share at least one point in common boundary (i.e., it is a queen adjacency).
```{r}
library(spdep)
nb <- spdep::poly2nb(data_2000, row.names = data_2000$color_code)

plot(data_2000$geometry)
plot(nb, coords = data_2000$geometry, col = "blue", lwd = 2, add = TRUE)
```

**Row-Standardized and Binary adjacency matrices**
This way to create a graph does not work with our data:
```{r}
nb
# This is not valid for our data
#W.adj_rs <- nb2mat(nb, style = "W")
#W.adj_B <- nb2mat(nb, style = "B")
```

The required formula needed by INLA to fit a model with our covariates has the following form:

```{r}
formula_2000 <- E3CI_diff ~ 1 + CO2_diff + GDP_diff +  FA_diff
```

This is the formula containing only the fixed effects.

First of all, a model with i.i.d. random effects will be fit to the data. This will provide a baseline to assess whether spatial random effects are really required when modeling these data. 

- Add the random iid effect to the formula:

```{r}
# Add ID column to add random effects
data_2000$ID <- 1:nrow(data_2000)

# Update the formula
formula_2000_1 <- update(formula_2000, . ~. + f(ID,model = "iid"))
```

And, now fit the model

```{r}
model_2000_iid <- inla(formula = formula_2000_1, data = data_2000,
  control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
  control.predictor = list(compute = TRUE))

summary(model_2000_iid)
model_2000_iid$summary.fixed
```

Now, three models will be considered:

- Besag's proper spatial model: `besag`
- Besag's improper spatial model: `besagproper`
- Besag-York-Mollié (convolution of an intrinsic CAR model and iid Gaussian model):`bym`

We also fit a standard (Bayesian) linear regression to see how important it is to include spatial dependence.

To fit these models, we need to create a *graph* from the adjacency matrix (it is the format required from INLA):

```{r}
nb2INLA("map.adj", nb)
g <- inla.read.graph(filename = "map.adj")
```


```{r, message=FALSE}
# if (!require("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("Rgraphviz")
library(Rgraphviz)
plot(g)
```

```{r}
formula_lm <- formula_2000 # f() = NULL
formula_besag <- update(formula_2000, . ~. + f(ID, model = "besag",graph = g))
formula_besg_proper <- update(formula_2000, . ~. + f(ID, model = "besagproper",graph = g))
formula_bym <- update(formula_2000, . ~. + f(ID, model = "bym",graph = g))

model_2000_lm <- inla(formula = formula_lm, data = data_2000,
  control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
  control.predictor = list(compute = TRUE))

model_2000_besag <- inla(formula = formula_besag, data = data_2000,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))
model_2000_besagprop <- inla(formula = formula_besg_proper, data = data_2000,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))
model_2000_bym <- inla(formula = formula_bym, data = data_2000, family = "gaussian",
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))

```

```{r}
results <- data.frame("E3CI_real" = data_2000$E3CI_diff,"IID" = model_2000_iid$summary.fitted.values[,"mean"],"Linear_Regression" = model_2000_lm$summary.fitted.values[,"mean"], "Besag" = model_2000_besag$summary.fitted.values[,"mean"], "BesagProper" = model_2000_besagprop$summary.fitted.values[,"mean"], "BYM" = model_2000_bym$summary.fitted.values[,"mean"])

mse <- function(real,fitted){
  return(mean((real - fitted)^2))
}


results_df <- cbind(data_2000, results)
```

#### Model Comparison

```{r}
percentage_diff_sign <- function(vector1, vector2) {
  # Check that the vectors have the same length
  if (length(vector1) != length(vector2)) {
    stop("The vectors must have the same length.")
  }
  
  # Calculate the number of elements with differing signs
  diff_signs <- sum(sign(vector1) != sign(vector2))
  
  # Calculate the percentage
  percentage <- (diff_signs / length(vector1)) * 100
  
  return(percentage)
}
```


```{r}
map2000_lm <- ggplot(data = results_df) +
  geom_sf(aes(fill = Linear_Regression )) + 
  labs(fill = "Fitted ERA5 - Linear regression") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2000_iid <- ggplot(data = results_df) +
  geom_sf(aes(fill = IID)) + 
  labs(fill = "Fitted ERA5 - IID model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2000_besag <- ggplot(data = results_df) +
  geom_sf(aes(fill = Besag)) + 
  labs(fill = "Fitted ERA5 - Besag Model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2000_besagproper <- ggplot(data = results_df) +
  geom_sf(aes(fill = BesagProper)) + 
  labs(fill = "Fitted ERA5 - BesagProper Model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2000_bym <- ggplot(data = results_df) +
  geom_sf(aes(fill = BYM)) + 
  labs(fill = "Fitted ERA5 - BYM model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2000_diff
map2000_lm
map2000_iid
map2000_besag
map2000_besagproper
map2000_bym
```

Let us create a joint visualisation:

```{r}
combined_df <- results_df %>%
  select(geometry, E3CI_diff,Linear_Regression, IID, Besag, BesagProper, BYM) %>%
  pivot_longer(cols = c(E3CI_diff,Linear_Regression, IID, Besag, BesagProper, BYM), 
               names_to = "Model", 
               values_to = "Value")

combined_map2000 <- ggplot(combined_df) +
  geom_sf(aes(fill = Value)) + 
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red") +
  facet_wrap(~ Model, ncol = 3) +
  labs(fill = "Value") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())

print(combined_map2000)
```



Different available criteria for model selection:

- `MSE` (on train partition)

```{r}
MSE_2000 <- c(mse(data_2000$E3CI_diff, fitted = results$E3CI_real),mse(data_2000$E3CI_diff, fitted = results$Linear_Regression),mse(data_2000$E3CI_diff, fitted = results$IID), mse(data_2000$E3CI_diff, fitted = results$Besag), mse(data_2000$E3CI_diff, fitted = results$BesagProper), mse(data_2000$E3CI_diff, fitted = results$BYM))
```


- `cpo` can be computed in the following way:
```{r}
cpo <- function(inla_model){
  return(-sum(log(inla_model$cpo$cpo)))
}
cpo_lm <- cpo(model_2000_lm)
cpo_besag <- cpo(model_2000_besag)
cpo_iid <- cpo(model_2000_iid)
cpo_besagproper <- cpo(model_2000_besagprop)
cpo_bym <- cpo(model_2000_bym)

CPOs <- c(cpo_lm,cpo_iid,cpo_besag,cpo_besagproper,cpo_bym)
```

- `marginal likelihood`:
```{r}
MLIKs <- c(model_2000_lm$mlik[[1,1]],model_2000_iid$mlik[[1,1]],model_2000_besag$mlik[[1,1]],model_2000_besagprop$mlik[[1,1]],model_2000_bym$mlik[[1,1]])
```

- `DIC`
```{r}
DICs <- WAICs <- c(model_2000_lm$dic$dic,model_2000_iid$dic$dic,model_2000_besag$dic$dic,model_2000_besagprop$dic$dic,model_2000_bym$dic$dic)
```

- `WAIC` 
```{r}
WAICs <- c(model_2000_lm$waic$waic,model_2000_iid$waic$waic,model_2000_besag$waic$waic,model_2000_besagprop$waic$waic,model_2000_bym$waic$waic)
```

```{r}
errors_df <- data.frame("Model" = c("Linear Regression","IID", "Besag", "BesagProper", "BYM"), 
               "WAIC" = WAICs,
               "MLIK" = MLIKs,
               "CPO" = CPOs,
               "DIC" = DICs,
               "MSE" = MSE_2000[2:length(MSE_2000)])

library(kableExtra)
kable(errors_df)
xtable::xtable(errors_df, digits = 7)
```

##### Posterior Information

```{r}
summary(model_2000_bym)
model_2000_bym$summary.fixed[,1:6]
model_2000_bym$summary.hyperpar
```



#### Model Hypothesis
Let us check some standard model hypotheses

##### Gaussian Likelihood

```{r}
qqnorm(data_2000$E3CI_diff)
qqline(data_2000$E3CI_diff,col="red")
shapiro.test(data_2000$E3CI_diff)
```


##### Residuals Normality

```{r}
resid_2000 <- results_df$BYM - results_df$E3CI_real 

qqnorm(resid_2000)
qqline(resid_2000,col="red")
shapiro.test(resid_2000)
```
We observe that, there normality is not specially fulfilled in the lower tails, but the p-value is greater than a 0.05 significance level, so that we can not discard normality.


##### Linearity

```{r}
results_df$residuals_bym <- resid_2000
results_df <- results_df %>%
  mutate(standardized_residuals = residuals_bym / sd(residuals_bym))

plot1 <- ggplot(results_df, aes(x = GDP_diff, y = standardized_residuals)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Residuals vs GDP_diff", x = "GDP_diff", y = "Residuals") +
  theme_minimal()

plot2 <- ggplot(results_df, aes(x = CO2_diff, y = standardized_residuals)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Residuals vs CO2_diff", x = "CO2_diff", y = "Residuals") +
  theme_minimal()

plot3 <- ggplot(results_df, aes(x = FA_diff, y = standardized_residuals)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Residuals vs FA_diff", x = "FA_diff", y = "Residuals") +
  theme_minimal()

# Combine the plots into a single plot
combined_plot <- plot_grid(plot1, plot2, plot3, ncol = 2)

# Display the combined plot
print(combined_plot)
```

The linearity is not fulfilled at all. But there is no a clear patterns to think that the values can not be randomly distributed around the line.

##### Homocedasticity

```{r}
results_df <- results_df %>%
  mutate(standardized_residuals = residuals_bym / sd(residuals_bym))

# Plot standardized residuals vs fitted values
homoscedasticity_plot <- ggplot(results_df, aes(x = BYM, y = standardized_residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "blue") +
  labs(title = "Standardized Residuals vs Fitted Values", 
       x = "Fitted Values", 
       y = "Standardized Residuals") +
  theme_minimal() +
  theme(panel.grid = element_blank(), axis.text = element_blank(), axis.ticks = element_blank())

print(homoscedasticity_plot)
```


##### Independence

```{r}
library(lmtest)

# Durbin-Watson
dw_test <- dwtest(resid_2000 ~ model_2000_bym$summary.fitted.values[,"mean"])
print(dw_test)
```


##### Outliers/Gaussian Likelihood
The models that INLA fits assume a lot of structure LGM+GMRF. However, this model specification allows for different likelihoods. We have specified `family = gaussian` in each model. This allows us to check whether the observed response values are likely to follow a normal distribution. We proceed with a *shapiro test*. The null hypothesis is then that the sample is normally distributed.

```{r}
test2000 <- shapiro.test(data_2000$E3CI_diff)
test2000$p.value
```

The p-value of `r test2000$p.value` says that there is no enough evidence to reject that our sample comes from a Normal population.

```{r}
qqnorm(data_2000$E3CI_diff)
qqline(data_2000$E3CI_diff, col = "red")
```


#### Predictions 

To predict with INLA, we need to fit the model again, but include `NA` in the response observations for which we want to do posterior inference.

Let us redesign de data by adding the observations to predict with *NA* in the response

```{r}
data_2000_bench <- NULL # to save the real values of E3CI
for(i in c(2000:2005)){
  data_2000_bench <- rbind(data_2000_bench,select_year_diff(year = i))
}

rows2000 <- which(data_2000_bench$Year == 2000)
rows2001 <- which(data_2000_bench$Year == 2001)
rows2002 <- which(data_2000_bench$Year == 2002)
rows2003 <- which(data_2000_bench$Year == 2003)
rows2004 <- which(data_2000_bench$Year == 2004)
rows2005 <- which(data_2000_bench$Year == 2005)

data_2000_preds <- data_2000_bench # Where we include the fitted values
data_2000_preds$E3CI_diff[rows2001] = NA
data_2000_preds$E3CI_diff[rows2002] = NA
data_2000_preds$E3CI_diff[rows2003] = NA
data_2000_preds$E3CI_diff[rows2004] = NA
data_2000_preds$E3CI_diff[rows2005] = NA
#View(data_2000_preds)
#View(data_2000_bench)
```

We are going to predict only with the best model in each case, which is the *BYM*. 

```{r}
data_2000_preds$ID <- as.numeric(as.factor(data_2000_preds$color_code))

# Model
model_2000_bym_pred <- inla(formula = formula_bym, data = data_2000_preds,family = "gaussian",
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))

data_2000_preds$fitted <- model_2000_bym_pred$summary.fitted.values[,"mean"]

data_2000_preds <- data_2000_preds %>% relocate(fitted, .after = E3CI_diff) %>% relocate(Year, .before = E3CI_diff) %>% relocate(color_code, .before = Year)
```

Visualization

- 2000: real vs fitted
```{r}
map2000_pred_train <- ggplot(data = data_2000_preds[rows2000,]) +
  geom_sf(aes(fill = fitted)) + 
  labs(fill = "Predicted ERA5 - 2000") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2000_diff
map2000_pred_train

MSE_2000_00 <- mse(data_2000_preds[rows2000,]$E3CI_diff, data_2000_preds[rows2000,]$fitted)
signerror2000_00 <- percentage_diff_sign(data_2000_preds[rows2000,]$E3CI_diff, data_2000_preds[rows2000,]$fitted)
```

- 2001: real vs predicted
```{r}
map2001_real <- ggplot(data = data_2000_bench[rows2001,]) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "Real ERA5 - 2001") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2001_pred <- ggplot(data = data_2000_preds[rows2001,]) +
  geom_sf(aes(fill = fitted)) + 
  labs(fill = "Predicted ERA5 - 2001") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2001_real
map2001_pred

MSE_2001_00 <- mse(data_2000_bench[rows2001,]$E3CI_diff, data_2000_preds[rows2001,]$fitted)
signerror2001_00 <- percentage_diff_sign(data_2000_bench[rows2001,]$E3CI_diff, data_2000_preds[rows2001,]$fitted)
```

-2002: real vs predicted
```{r}
map2002_real <- ggplot(data = data_2000_bench[rows2002,]) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "Real ERA5 - 2002") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2002_pred <- ggplot(data = data_2000_preds[rows2002,]) +
  geom_sf(aes(fill = fitted)) + 
  labs(fill = "Predicted ERA5 - 2002") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2002_real
map2002_pred

MSE_2002_00 <- mse(data_2000_bench[rows2002,]$E3CI_diff, data_2000_preds[rows2002,]$fitted)
signerror2002_00 <- percentage_diff_sign(data_2000_bench[rows2002,]$E3CI_diff, data_2000_preds[rows2002,]$fitted)
```


-2003: real vs predicted
```{r}
map2003_real <- ggplot(data = data_2000_bench[rows2003,]) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "Real ERA5 - 2003") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2003_pred <- ggplot(data = data_2000_preds[rows2003,]) +
  geom_sf(aes(fill = fitted)) + 
  labs(fill = "Predicted ERA5 - 2003") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2003_real
map2003_pred

MSE_2003_00 <- mse(data_2000_bench[rows2003,]$E3CI_diff, data_2000_preds[rows2003,]$fitted)
signerror2003_00 <- percentage_diff_sign(data_2000_bench[rows2003,]$E3CI_diff, data_2000_preds[rows2003,]$fitted)
```

```{r}
map2004_real <- ggplot(data = data_2000_bench[rows2004,]) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "Real ERA5 - 2004") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2004_pred <- ggplot(data = data_2000_preds[rows2004,]) +
  geom_sf(aes(fill = fitted)) + 
  labs(fill = "Predicted ERA5 - 2004") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2004_real
map2004_pred

MSE_2004_00 <- mse(data_2000_bench[rows2004,]$E3CI_diff, data_2000_preds[rows2004,]$fitted)
signerror2004_00 <- percentage_diff_sign(data_2000_bench[rows2004,]$E3CI_diff, data_2000_preds[rows2004,]$fitted)
```

```{r}
map2005_real <- ggplot(data = data_2000_bench[rows2005,]) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "Real ERA5 - 2005") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2005_pred <- ggplot(data = data_2000_preds[rows2005,]) +
  geom_sf(aes(fill = fitted)) + 
  labs(fill = "Predicted ERA5 - 2005") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2005_real
map2005_pred

MSE_2005_00 <- mse(data_2000_bench[rows2005,]$E3CI_diff, data_2000_preds[rows2005,]$fitted)
signerror2005_00 <- percentage_diff_sign(data_2000_bench[rows2005,]$E3CI_diff, data_2000_preds[rows2005,]$fitted)
```


We can try to represent together this predictions 

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(sf)

data_2000_preds$E3CI_diff <- data_2000_bench$E3CI_diff

# Filter data for the years 2001, 2002, 2003, 2004 and 2005
filtered_data <- data_2000_preds %>%
  filter(Year %in% c(2001, 2002, 2003,2004,2005))

# Create a combined data frame for the necessary years and variables
combined_df <- filtered_data %>%
  select(geometry, Year, E3CI_diff, fitted) %>%
  pivot_longer(cols = c(E3CI_diff, fitted), 
               names_to = "Variable", 
               values_to = "Value") %>%
  unite("Year_Variable", Year, Variable, sep = "_")

# Create the combined plot with facets
combined_map <- ggplot(combined_df) +
  geom_sf(aes(fill = Value)) + 
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red") +
  facet_wrap(~ Year_Variable, ncol = 5) +
  labs(fill = "Value") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold", size = 12),
        legend.position = "right") # Change legend position to the right

# Display the combined plot
print(combined_map)
```

```{r}
mse2000 = mse(real = data_2000_preds$E3CI_diff[rows2000], fitted = data_2000_preds$fitted[rows2000])
mse2001 = mse(real = data_2000_preds$E3CI_diff[rows2001], fitted = data_2000_preds$fitted[rows2001])
mse2002 = mse(real = data_2000_preds$E3CI_diff[rows2002], fitted = data_2000_preds$fitted[rows2002])
mse2003 = mse(real = data_2000_preds$E3CI_diff[rows2003], fitted = data_2000_preds$fitted[rows2003])


MSE_preds_2000 <- data_frame("Year" = 2000:2003,
                             "MSE" = c(mse2000,mse2001,mse2002,mse2003),
                             "Set" = c("Train", "Test","Test","Test"))

kable(MSE_preds_2000)
```


### MODEL 2021

One idea is to use the last year available 2021, to predict the 2022.

#### Filtering year 2021

We use the `select_year_diff` defined before.

```{r}
data_2021 <- select_year_diff(2021)
head(data_2021[,c("color_code","E3CI_diff","GDP_diff","CO2_diff","GHG_diff","FA_diff","Year")])
```

#### E3CI map

```{r}
map2021 <- ggplot(data = data_2021) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "ERA5 - Risk Index") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")
  

map2021
```


We repeat the same process than in the 2000 case
```{r}
nb <- spdep::poly2nb(data_2021, row.names = data_2021$color_code)
```

Base formula
```{r}
formula_2021<- E3CI_diff ~ 1 + CO2_diff + GDP_diff + FA_diff
```

#### IID
```{r}
# Add ID column to add random effects
data_2021$ID <- 1:nrow(data_2021)
# Update the formula
formula_2021_1 <- update(formula_2021, . ~. + f(ID,model = "iid"))

model_2021_iid <- inla(formula = formula_2021_1, data = data_2021,
  control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
  control.predictor = list(compute = TRUE))

```

#### Besag
```{r}
formula_besag_2021 <- update(formula_2021, . ~. + f(ID, model = "besag",graph = g))

model_2021_besag <- inla(formula = formula_besag_2021, data = data_2021,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))

```


#### Besag Proper
```{r}
formula_besg_proper_2021 <- update(formula_2021, . ~. + f(ID, model = "besagproper",graph = g))

model_2021_besagprop <- inla(formula = formula_besg_proper_2021, data = data_2021,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))
```


#### Bym
```{r}
formula_bym_2021 <- update(formula_2021, . ~. + f(ID, model = "bym",graph = g))

model_2021_bym <- inla(formula = formula_bym_2021, data = data_2021,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))
```

#### Model Comparison
```{r}
results2021 <- data.frame("E3CI_real" = data_2021$E3CI_diff,"IID" = model_2021_iid$summary.fitted.values[,"mean"], "Besag" = model_2021_besag$summary.fitted.values[,"mean"], "BesagProper" = model_2021_besagprop$summary.fitted.values[,"mean"], "BYM" = model_2021_bym$summary.fitted.values[,"mean"])


results2021_df <- cbind(data_2021, results2021)
```

```{r}
map2021_iid <- ggplot(data = results2021_df) +
  geom_sf(aes(fill = IID)) + 
  labs(fill = "Fitted ERA5 - IID model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2021_besag <- ggplot(data = results2021_df) +
  geom_sf(aes(fill = Besag)) + 
  labs(fill = "Fitted ERA5 - Besag Model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2021_besagproper <- ggplot(data = results2021_df) +
  geom_sf(aes(fill = BesagProper)) + 
  labs(fill = "Fitted ERA5 - BesagProper Model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2021_bym <- ggplot(data = results2021_df) +
  geom_sf(aes(fill = BYM)) + 
  labs(fill = "Fitted ERA5 - BYM model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2021
map2021_iid
map2021_besag
map2021_besagproper
map2021_bym
```

Different available criteria for model selection:

- `MSE` (on train partition)

```{r}
MSE_2021 <- c(mse(data_2021$E3CI_diff, fitted = results2021$E3CI_real),mse(results2021$E3CI_real, fitted = results2021$IID), mse(results2021$E3CI_real, fitted = results2021$Besag), mse(results2021$E3CI_real, fitted = results2021$BesagProper), mse(results2021$E3CI_real, fitted = results2021$BYM))
```


- `cpo` can be computed in the following way:
```{r}
cpo <- function(inla_model){
  return(-sum(log(inla_model$cpo$cpo)))
}

cpo_besag <- cpo(model_2021_besag)
cpo_iid <- cpo(model_2021_iid)
cpo_besagproper <- cpo(model_2021_besagprop)
cpo_bym <- cpo(model_2021_bym)

CPOs2021 <- c(cpo_iid,cpo_besag,cpo_besagproper,cpo_bym)
```

- `marginal likelihood`:
```{r}
MLIKs2021 <- c(model_2021_iid$mlik[[1,1]],model_2021_besag$mlik[[1,1]],model_2021_besagprop$mlik[[1,1]],model_2021_bym$mlik[[1,1]])
```

- `DIC`
```{r}
DICs2021 <- c(model_2021_iid$dic$dic,model_2021_besag$dic$dic,model_2021_besagprop$dic$dic,model_2021_bym$dic$dic)
```

- `WAIC` 
```{r}
WAICs2021 <- c(model_2021_iid$waic$waic,model_2021_besag$waic$waic,model_2021_besagprop$waic$waic,model_2021_bym$waic$waic)
```

```{r}
errors2021_df <- data.frame("Model" = c("IID", "Besag", "BesagProper", "BYM"), 
               "WAIC" = WAICs2021,
               "MLIK" = MLIKs2021,
               "CPO" = CPOs2021,
               "DIC" = DICs2021,
               "MSE" = MSE_2021[2:length(MSE_2021)])

library(kableExtra)
kable(errors2021_df)
```



#### Model Hypothesis
Let us check some standard model hypotheses

##### Residuals Normality

```{r}
resid_2021 <- results2021_df$BYM - results2021_df$E3CI_real

qqnorm(resid_2021)
qqline(resid_2021,col="red")
shapiro.test(resid_2021)
```
This is due to the outlier.


##### Linearity

```{r}
results2021_df$residuals_bym <- resid_2021
results2021_df <- results2021_df %>%
  mutate(standardized_residuals = residuals_bym / sd(residuals_bym))

plot11 <- ggplot(results2021_df, aes(x = GDP_diff, y = standardized_residuals)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Residuals vs GDP_diff", x = "GDP_diff", y = "Residuals") +
  theme_minimal()

plot12 <-ggplot(results2021_df, aes(x = CO2_diff, y = standardized_residuals)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Residuals vs CO2_diff", x = "CO2_diff", y = "Residuals") +
  theme_minimal()

plot13 <-ggplot(results2021_df, aes(x = FA_diff, y = standardized_residuals)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Residuals vs FA_diff", x = "FA_diff", y = "Residuals") +
  theme_minimal()

combined_plot2 <- plot_grid(plot11,plot12,plot13,ncol = 2)
print(combined_plot2)
```

The linearity is not fulfilled at all. But there is no a clear patterns to think that the values can not be randomly distributed around the line.

##### Homocedasticity

```{r}
# Plot standardized residuals vs fitted values
homoscedasticity_plot <- ggplot(results2021_df, aes(x = BYM, y = standardized_residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "blue") +
  labs(title = "Standardized Residuals vs Fitted Values", 
       x = "Fitted Values", 
       y = "Standardized Residuals") +
  theme_minimal() +
  theme(panel.grid = element_blank(), axis.text = element_blank(), axis.ticks = element_blank())

print(homoscedasticity_plot)
```


##### Independence

```{r}
library(lmtest)

# Durbin-Watson
dw_test <- dwtest(resid_2021 ~ model_2021_bym$summary.fitted.values[,"mean"])
print(dw_test)
```



```{r}
test2021 <- shapiro.test(data_2021$E3CI_diff)
test2021$p.value
```

In contrast to the year 2000, the normality hypothesis is much more violated. However, the p value is `r test2021$p.value`, so that "it could be assumed normality of the data".  

```{r}
qqnorm(data_2021$E3CI_diff)
qqline(data_2021$E3CI_diff, col = "red")
```

#### Predictions

We need to fit the model again, but include `NA` in the response observations for which we want to do posterior inference.

Let us redesign de data by adding the 2022 observations with *NA* in the response

```{r}
data_2021_bench <- NULL # to save the real values of E3CI
for(i in c(2021:2022)){
  data_2021_bench <- rbind(data_2021_bench,select_year_diff(year = i))
}

rows2021 <- which(data_2021_bench$Year == 2021)
rows2022 <- which(data_2021_bench$Year == 2022)

data_2021_preds <- data_2021_bench # Where we include the fitted values
data_2021_preds$E3CI_diff[rows2022] = NA
```

We are going to predict only with the best model in each case, which is the *BYM*. 

```{r}
data_2021_preds$ID <- as.numeric(as.factor(data_2021_preds$color_code))

# Model
model_2021_bym_pred <- inla(formula = formula_bym, data = data_2021_preds,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))

data_2021_preds$fitted <- model_2021_bym_pred$summary.fitted.values[,"mean"]

data_2021_preds <- data_2021_preds %>% relocate(fitted, .after = E3CI_diff) %>% relocate(Year, .before = E3CI_diff) %>% relocate(color_code, .before = Year)
```

One idea is to use the last year available 2021, to predict the 2022.

Visualization

- 2021: real vs fitted
```{r}
library(gridExtra)
map2021
map2021_bym
```


```{r}
map2022_real <- ggplot(data = data_2021_bench[rows2022,]) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "Real ERA5 - 2022") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())

# Create a plot for the predicted data for 2022
map2022_pred <- ggplot(data = data_2021_preds[rows2022,]) +
  geom_sf(aes(fill = fitted)) + 
  labs(fill = "Predicted ERA5 - 2022") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())

map2022_real
map2022_pred
```

Combined plots 

```{r}
library(cowplot)

# Define rows for the year 2021
rows2021 <- which(results2021_df$Year == 2021)

# Create a plot for the real data for 2021
map2021_real <- ggplot(data = results2021_df[rows2021,]) +
  geom_sf(aes(fill = E3CI_diff)) + 
  labs(fill = "Real ERA5 - 2021") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold", size = 12))

# Create a plot for the BYM model fitted data for 2021
map2021_bym <- ggplot(data = results2021_df[rows2021,]) +
  geom_sf(aes(fill = BYM)) + 
  labs(fill = "Fitted ERA5 - BYM model 2021") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold", size = 12))

```

```{r}
# Filter data for the year 2022
rows2022 <- which(data_2021_bench$Year == 2022)
data_2022_real <- data_2021_bench[rows2022, ]
data_2022_pred <- data_2021_preds[rows2022, ]

# Create a combined dataframe for the real and predicted values of 2022
combined_2022 <- bind_rows(
  data_2022_real %>% mutate(Variable = "E3CI_diff", Value = E3CI_diff),
  data_2022_pred %>% mutate(Variable = "fitted", Value = fitted)
) %>%
  select(geometry, Variable, Value) %>%
  mutate(Year_Variable = paste0("2022_", Variable))

# Create the combined plot with facets
combined_map_2022 <- ggplot(combined_2022) +
  geom_sf(aes(fill = Value)) + 
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red") +
  facet_wrap(~ Year_Variable, ncol = 2) +
  labs(fill = "Value") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold", size = 12),
        legend.position = "right") # Change legend position to the right

# Display the combined plot
print(combined_map_2022)
```


```{r}
# Combine the two plots into a single plot with facets
combined_map_preds21 <- plot_grid(map2021_real, map2021_bym, map2022_real,map2022_pred, 
                                  ncol = 2)

# Display the combined plot
print(combined_map_preds21)
```


### MODEL 2022
The idea of this section is to fit a model with the latest available data. We will then use a forecasting method to predict the covariates for the following years and try some "real fire" predictions of the E3CI index for future years. 

#### Filtering year 2022

We use the `select_year_diff` defined before.

```{r}
data_2022 <- select_year_diff(2022)
head(data_2022[,c("color_code","E3CI","GDP_diff","CO2_diff","GHG_diff","FA_diff","Year")])

```

#### E3CI map

```{r}
map2022 <- ggplot(data = data_2022) +
  geom_sf(aes(fill = E3CI)) + 
  labs(fill = "ERA5 - Risk Index") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")
  

map2022
```


We repeat the same process than in the before cases
```{r}
nb <- spdep::poly2nb(data_2022, row.names = data_2022$color_code)
```

Base formula
```{r}
formula_2022<- E3CI ~ 1 + CO2_diff + GDP_diff + FA_diff
```

#### IID
```{r}
# Add ID column to add random effects
data_2022$ID <- 1:nrow(data_2022)
# Update the formula
formula_2022_1 <- update(formula_2022, . ~. + f(ID,model = "iid"))

model_2022_iid <- inla(formula = formula_2022_1, data = data_2022,
  control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
  control.predictor = list(compute = TRUE))

```

#### Besag
```{r}
formula_besag_2022 <- update(formula_2022, . ~. + f(ID, model = "besag",graph = g))

model_2022_besag <- inla(formula = formula_besag_2022, data = data_2022,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))

```


#### Besag Proper
```{r}
formula_besg_proper_2022 <- update(formula_2022, . ~. + f(ID, model = "besagproper",graph = g))

model_2022_besagprop <- inla(formula = formula_besg_proper_2022, data = data_2022,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))
```


#### Bym
```{r}
formula_bym_2022 <- update(formula_2022, . ~. + f(ID, model = "bym",graph = g))

model_2022_bym <- inla(formula = formula_bym_2022, data = data_2022,
                         control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                         control.predictor = list(compute = TRUE))
```

#### Model Comparison
```{r}
results2022 <- data.frame("E3CI_real" = data_2022$E3CI,"IID" = model_2022_iid$summary.fitted.values[,"mean"], "Besag" = model_2022_besag$summary.fitted.values[,"mean"], "BesagProper" = model_2022_besagprop$summary.fitted.values[,"mean"], "BYM" = model_2022_bym$summary.fitted.values[,"mean"])


results2022_df <- cbind(data_2022, results2022)
```

```{r}
map2022_iid <- ggplot(data = results2022_df) +
  geom_sf(aes(fill = IID)) + 
  labs(fill = "Fitted ERA5 - IID model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2022_besag <- ggplot(data = results2022_df) +
  geom_sf(aes(fill = Besag)) + 
  labs(fill = "Fitted ERA5 - Besag Model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2022_besagproper <- ggplot(data = results2022_df) +
  geom_sf(aes(fill = BesagProper)) + 
  labs(fill = "Fitted ERA5 - BesagProper Model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2022_bym <- ggplot(data = results2022_df) +
  geom_sf(aes(fill = BYM)) + 
  labs(fill = "Fitted ERA5 - BYM model") +
  scale_fill_gradient2(
    midpoint = 0, low = "blue", mid = "white", high = "red")

map2022
map2022_iid
map2022_besag
map2022_besagproper
map2022_bym
```

Different available criteria for model selection:

- `MSE` (on train partition)

```{r}
MSE_2022 <- c(mse(data_2022$E3CI, fitted = results2022$E3CI_real),mse(data_2022$E3CI, fitted = results2022$IID), mse(data_2022$E3CI, fitted = results2022$Besag), mse(data_2022$E3CI, fitted = results2022$BesagProper), mse(data_2022$E3CI, fitted = results2022$BYM))
```


- `cpo` can be computed in the following way:
```{r}
cpo <- function(inla_model){
  return(-sum(log(inla_model$cpo$cpo)))
}

cpo_besag <- cpo(model_2022_besag)
cpo_iid <- cpo(model_2022_iid)
cpo_besagproper <- cpo(model_2022_besagprop)
cpo_bym <- cpo(model_2022_bym)

CPOs2022 <- c(cpo_iid,cpo_besag,cpo_besagproper,cpo_bym)
```

- `marginal likelihood`:
```{r}
MLIKs2022 <- c(model_2022_iid$mlik[[1,1]],model_2022_besag$mlik[[1,1]],model_2022_besagprop$mlik[[1,1]],model_2022_bym$mlik[[1,1]])
```

- `DIC`
```{r}
DICs2022 <- c(model_2022_iid$dic$dic,model_2022_besag$dic$dic,model_2022_besagprop$dic$dic,model_2022_bym$dic$dic)
```

- `WAIC` 
```{r}
WAICs2022 <- c(model_2022_iid$waic$waic,model_2022_besag$waic$waic,model_2022_besagprop$waic$waic,model_2022_bym$waic$waic)
```

```{r}
errors2022_df <- data.frame("Model" = c("IID", "Besag", "BesagProper", "BYM"), 
               "WAIC" = WAICs2022,
               "MLIK" = MLIKs2022,
               "CPO" = CPOs2022,
               "DIC" = DICs2022,
               "MSE" = MSE_2022[2:length(MSE_2022)])

library(kableExtra)
kable(errors2022_df)
```



#### Model Hypothesis

```{r}
test2022 <- shapiro.test(data_2022$E3CI)
test2022$p.value
```

Here the hypothesis is violated even more. Only with a pre-specified significance level of 0.01 do we not reject the null hypothesis. It is interesting to note that all the models are getting wrong as long as normality is violated, but the BYM model still fits the data well. 

```{r}
qqnorm(data_2022$E3CI)
qqline(data_2022$E3CI, col = "red")
```


#### Predictions

If predictions for future covariate years are obtained, we could refit this model to predict future years.






